{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with the population divide by races for each neighborhood\n",
    "# use neighborhood-separated articles\n",
    "# for each neighborhood, turn all articles into a spaCy-processible list of documents\n",
    "# for each list, extract out all people and run their last names with ethnicolr to predict races\n",
    "# for each set of predictions, get percentage of races\n",
    "# have journalism team go through U.S. Census data to see if the proportions of races match Census data\n",
    "\n",
    "# QUESTION: how to verify that two names talked about in an article belong to different people/the same people?\n",
    "\n",
    "# potential solution: for each article, only store the unique names; but is this possible? \n",
    "# each doc is an article, so we can extract out all \"PERSON\" entities and then keep only those which are unique\n",
    "# we could then feed the last names of those unique people (the last names may not necessarily be unique) to ethnicolr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load medium English model in case we need to work with vectors\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "# remove special characters and extra whitespace\n",
    "def remove_specChar(df):\n",
    "\n",
    "    spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\", \"*\",\"+\",\",\",\n",
    "                  \"-\",\".\",\"/\",\":\",\";\",\"<\", \"=\",\">\",\"?\",\"@\",\"[\",\n",
    "                  \"\\\\\",\"]\",\"^\",\"_\", \"`\",\"{\",\"|\",\"}\",\"~\",\"–\", \n",
    "                  \"\\xc2\", \"\\xa0\", \"\\x80\", \"\\x9c\", \"\\x99\", \"\\x94\", \n",
    "                  \"\\xad\", \"\\xe2\", \"\\x9d\", \"\\n\"]\n",
    "\n",
    "    #for char in spec_chars:\n",
    "    #    df['text'] = df['text'].str.strip()\n",
    "    #    df['text'] = df['text'].str.replace(char, ' ')\n",
    "        \n",
    "    \n",
    "    # access each column separately\n",
    "    for i in range(len(df.index)):\n",
    "        for col in df.columns:\n",
    "            for char in spec_chars:\n",
    "                try:\n",
    "                    df.loc[i, col] = df.loc[i, col].str.strip()\n",
    "                    df.loc[i, col] = df.loc[i, col].str.replace(char, ' ')\n",
    "                except:\n",
    "                    pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (500, 23)\n"
     ]
    }
   ],
   "source": [
    "# read in CSV of articles\n",
    "df = pd.read_csv('Neighborhood_Separated_Articles/2014.csv')\n",
    "\n",
    "df = remove_specChar(df)\n",
    "print(\"shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyde_park DONE\n",
      "beacon_hill DONE\n",
      "south_boston DONE\n",
      "jamaica_plain DONE\n",
      "east_boston DONE\n",
      "south_end DONE\n",
      "back_bay DONE\n",
      "north_end DONE\n",
      "west_roxbury DONE\n",
      "mission_hill DONE\n",
      "harbor_islands DONE\n",
      "west_end DONE\n",
      "longwood_medical_area DONE\n",
      "dorchester DONE\n",
      "roxbury DONE\n",
      "downtown DONE\n",
      "fenway DONE\n",
      "mattapan DONE\n",
      "brighton DONE\n",
      "charlestown DONE\n",
      "roslindale DONE\n",
      "allston DONE\n"
     ]
    }
   ],
   "source": [
    "articles = {'hyde_park': [], 'beacon_hill': [], 'south_boston': [], 'jamaica_plain': [], 'east_boston': [],\n",
    "                'south_end': [], 'back_bay': [], 'north_end': [], 'west_roxbury': [], 'mission_hill': [],\n",
    "                'harbor_islands': [], 'west_end': [], 'longwood_medical_area': [],\n",
    "                'dorchester': [], 'roxbury': [], 'downtown': [], 'fenway': [], 'mattapan': [], 'brighton': [],\n",
    "                'charlestown': [], 'roslindale': [], 'allston': []}\n",
    "for sub_neighborhood in articles.keys():\n",
    "    for i in range(df.shape[0]):\n",
    "        if type(df.loc[i, sub_neighborhood]) == str:\n",
    "            articles[sub_neighborhood].append(nlp(df.loc[i, sub_neighborhood]))\n",
    "    print(sub_neighborhood + ' DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ethnicolr import census_ln, pred_census_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyde_park 108\n",
      "beacon_hill 43\n",
      "south_boston 90\n",
      "jamaica_plain 61\n",
      "east_boston 23\n",
      "south_end 51\n",
      "back_bay 53\n",
      "north_end 11\n",
      "west_roxbury 54\n",
      "mission_hill 32\n",
      "harbor_islands 1\n",
      "west_end 8\n",
      "longwood_medical_area 0\n",
      "dorchester 500\n",
      "roxbury 218\n",
      "downtown 55\n",
      "fenway 16\n",
      "mattapan 52\n",
      "brighton 13\n",
      "charlestown 6\n",
      "roslindale 30\n",
      "allston 12\n"
     ]
    }
   ],
   "source": [
    "for key in articles.keys():\n",
    "    print(key + ' ' + str(len(articles[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {'hyde_park': [], 'beacon_hill': [], 'south_boston': [], 'jamaica_plain': [], 'east_boston': [],\n",
    "                'south_end': [], 'back_bay': [], 'north_end': [], 'west_roxbury': [], 'mission_hill': [],\n",
    "                'harbor_islands': [], 'west_end': [], 'longwood_medical_area': [],\n",
    "                'dorchester': [], 'roxbury': [], 'downtown': [], 'fenway': [], 'mattapan': [], 'brighton': [],\n",
    "                'charlestown': [], 'roslindale': [], 'allston': []}\n",
    "\n",
    "for sub_neighborhood in articles.keys():\n",
    "    for doc in articles[sub_neighborhood]:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                name = ent[0:2]\n",
    "                people[sub_neighborhood].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_neighborhood in people.keys():\n",
    "    list1 = people[sub_neighborhood]\n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    people[sub_neighborhood] = unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 12 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-967f0feb15da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mpeople\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_neighborhood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnames_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeople\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_neighborhood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnames_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mrepresentation_proportions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_neighborhood\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_census_ln\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2010\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ASUS\\anaconda3\\envs\\dcamm_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5153\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5154\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5155\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5156\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ASUS\\anaconda3\\envs\\dcamm_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ASUS\\anaconda3\\envs\\dcamm_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             raise ValueError(\n\u001b[1;32m--> 227\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 12 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "representation_proportions = {'hyde_park': [], 'beacon_hill': [], 'south_boston': [], 'jamaica_plain': [], 'east_boston': [],\n",
    "                'south_end': [], 'back_bay': [], 'north_end': [], 'west_roxbury': [], 'mission_hill': [],\n",
    "                'harbor_islands': [], 'west_end': [], 'longwood_medical_area': [],\n",
    "                'dorchester': [], 'roxbury': [], 'downtown': [], 'fenway': [], 'mattapan': [], 'brighton': [],\n",
    "                'charlestown': [], 'roslindale': [], 'allston': []}\n",
    "for sub_neighborhood in people.keys():\n",
    "    for i in range(len(people[sub_neighborhood])):\n",
    "        if people[sub_neighborhood][i].text.strip() != '':\n",
    "            temp = people[sub_neighborhood][i].text.split()\n",
    "            print()\n",
    "            if len(temp) > 1:\n",
    "                people[sub_neighborhood][i] = temp[-1]\n",
    "            else:\n",
    "                people[sub_neighborhood][i] = temp[0]\n",
    "    names_df = pd.DataFrame(people[sub_neighborhood])\n",
    "    names_df.columns = ['name']\n",
    "    representation_proportions[sub_neighborhood] = pred_census_ln(names_df, 'name', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>V</td>\n",
       "      <td>i</td>\n",
       "      <td>ñ</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>M</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>H</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>S</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>R</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     10    11\n",
       "0        None  None  None  None  None  None  None  None  None  None  None\n",
       "1     C     a     r     t     e     r  None  None  None  None  None  None\n",
       "2     B     u     r     k     e  None  None  None  None  None  None  None\n",
       "3     J     e     n     k     i     n     s  None  None  None  None  None\n",
       "4     S     h     a     w  None  None  None  None  None  None  None  None\n",
       "...  ..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "1170  V     i     ñ     o     l     y  None  None  None  None  None  None\n",
       "1171  M     o     r     r     i     s  None  None  None  None  None  None\n",
       "1172  H     e     r     n     a     n     d     e     z  None  None  None\n",
       "1173  S     h     a     w  None  None  None  None  None  None  None  None\n",
       "1174  R     o     s     i     e  None  None  None  None  None  None  None\n",
       "\n",
       "[1175 rows x 12 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rosie']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people[sub_neighborhood][i].strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize the data so that we have a way to retrieve original text\n",
    "# like adding ID to the dataset to identify each article\n",
    "# we should be able to find out the article a name comes from\n",
    "# we should also be able to find out which neighborhood an article talks about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If name has 'word', 'word', then take the first name\n",
    "# keep sentence where name occurred, okay if multiple sentences\n",
    "# look at sentence where the name was mentioned \n",
    "# and the words which were used\n",
    "# end up with a dataset which has 'name' + 'sentence' + 'race'\n",
    "# try to put ID of article in the dataset as well, next to the sentence\n",
    "# for now, try to keep the row from which the name comes, or at least some form of ID\n",
    "\n",
    "# if extra time, group sentences by associated race\n",
    "# find most frequently used words for each race, maybe a word cloud or something"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
