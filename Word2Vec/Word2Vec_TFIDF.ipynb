{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np # linear algebra\r\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
    "import gensim\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import random\r\n",
    "import gensim.models.doc2vec\r\n",
    "from wordcloud import WordCloud, STOPWORDS,ImageColorGenerator\r\n",
    "from gensim.models.doc2vec import Doc2Vec\r\n",
    "import numpy as np\r\n",
    "from os import path\r\n",
    "from PIL import Image\r\n",
    "from wordcloud import WordCloud, STOPWORDS \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import networkx as nx\r\n",
    "from random import randint \r\n",
    "from itertools import count\r\n",
    "import networkx as nx\r\n",
    "import ast\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from collections import Counter\r\n",
    "from num2words import num2words\r\n",
    "import openpyxl\r\n",
    "import nltk\r\n",
    "import os\r\n",
    "import string\r\n",
    "import numpy as np\r\n",
    "import copy\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "import re\r\n",
    "import math\r\n",
    "import ast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def convert_lower_case(data):\r\n",
    "    return np.char.lower(data)\r\n",
    "\r\n",
    "def remove_stop_words(data):\r\n",
    "    stop_words = stopwords.words('english')\r\n",
    "    words = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in words:\r\n",
    "        if w not in stop_words and len(w) > 1:\r\n",
    "            new_text = new_text + \" \" + w\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def remove_punctuation(data):\r\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\r\n",
    "    for i in range(len(symbols)):\r\n",
    "        data = np.char.replace(data, symbols[i], ' ')\r\n",
    "        data = np.char.replace(data, \"  \", \" \")\r\n",
    "    data = np.char.replace(data, ',', '')\r\n",
    "    return data\r\n",
    "\r\n",
    "def remove_apostrophe(data):\r\n",
    "    return np.char.replace(data, \"'\", \"\")\r\n",
    "\r\n",
    "def stemming(data):\r\n",
    "    stemmer= PorterStemmer()\r\n",
    "    \r\n",
    "    tokens = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in tokens:\r\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def convert_numbers(data):\r\n",
    "    tokens = word_tokenize(str(data))\r\n",
    "    new_text = \"\"\r\n",
    "    for w in tokens:\r\n",
    "        try:\r\n",
    "            w = num2words(int(w))\r\n",
    "        except:\r\n",
    "            a = 0\r\n",
    "        new_text = new_text + \" \" + w\r\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\r\n",
    "    return new_text\r\n",
    "\r\n",
    "def preprocess(data):\r\n",
    "    data = convert_lower_case(data)\r\n",
    "    data = remove_punctuation(data) #remove comma seperately\r\n",
    "    data = remove_apostrophe(data)\r\n",
    "    data = remove_stop_words(data)\r\n",
    "    data = convert_numbers(data)\r\n",
    "    # data = stemming(data)\r\n",
    "    data = remove_punctuation(data)\r\n",
    "    data = convert_numbers(data)\r\n",
    "    # data = stemming(data) #needed again as we need to stem the words\r\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\r\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df = pd.read_csv('../Entity_Recognition/Neighborhood_Separated_Articles/2014.csv')\r\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df = df.fillna(\"('no article', 'no_id')\")\r\n",
    "df['dorchester'] = df['dorchester'].apply(ast.literal_eval)\r\n",
    "df['roxbury'] = df['roxbury'].apply(ast.literal_eval)\r\n",
    "df['mattapan'] = df['mattapan'].apply(ast.literal_eval)\r\n",
    "df['hyde_park'] = df['hyde_park'].apply(ast.literal_eval)\r\n",
    "df['fenway'] = df['fenway'].apply(ast.literal_eval)\r\n",
    "df['beacon_hill'] = df['beacon_hill'].apply(ast.literal_eval)\r\n",
    "df['downtown'] = df['downtown'].apply(ast.literal_eval)\r\n",
    "df['south_boston'] = df['south_boston'].apply(ast.literal_eval)\r\n",
    "df['east_boston'] = df['east_boston'].apply(ast.literal_eval)\r\n",
    "df['back_bay'] = df['back_bay'].apply(ast.literal_eval)\r\n",
    "df['jamaica_plain'] = df['jamaica_plain'].apply(ast.literal_eval)\r\n",
    "df['south_end'] = df['south_end'].apply(ast.literal_eval)\r\n",
    "df['charlestown'] = df['charlestown'].apply(ast.literal_eval)\r\n",
    "df['brighton'] = df['brighton'].apply(ast.literal_eval)\r\n",
    "df['allston'] = df['allston'].apply(ast.literal_eval)\r\n",
    "df['west_end'] = df['west_end'].apply(ast.literal_eval)\r\n",
    "df['roslindale'] = df['roslindale'].apply(ast.literal_eval)\r\n",
    "df['north_end'] = df['north_end'].apply(ast.literal_eval)\r\n",
    "df['mission_hill'] = df['mission_hill'].apply(ast.literal_eval)\r\n",
    "df['harbor_islands'] = df['harbor_islands'].apply(ast.literal_eval)\r\n",
    "df['longwood_medical_area'] = df['longwood_medical_area'].apply(ast.literal_eval)\r\n",
    "df['west_roxbury'] = df['west_roxbury'].apply(ast.literal_eval)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "documents = {'hyde_park': [], 'beacon_hill': [], 'south_boston': [], 'jamaica_plain': [], 'east_boston': [],\r\n",
    "                'south_end': [], 'back_bay': [], 'north_end': [], 'west_roxbury': [], 'mission_hill': [],\r\n",
    "                'harbor_islands': [], 'west_end': [], 'longwood_medical_area': [],\r\n",
    "                'dorchester': [], 'roxbury': [], 'downtown': [], 'fenway': [], 'mattapan': [], 'brighton': [],\r\n",
    "                'charlestown': [], 'roslindale': [], 'allston': []}\r\n",
    "\r\n",
    "for col in df.columns:\r\n",
    "    tokens = []\r\n",
    "    for i in range(df.shape[0]):\r\n",
    "        article, _ = df.loc[i][col]\r\n",
    "        if article != 'no article':\r\n",
    "            text = word_tokenize(preprocess(article))\r\n",
    "            tokens = tokens + text\r\n",
    "    documents[col] = tokens\r\n",
    "    print(col)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dorchester\n",
      "roxbury\n",
      "mattapan\n",
      "hyde_park\n",
      "fenway\n",
      "beacon_hill\n",
      "downtown\n",
      "south_boston\n",
      "east_boston\n",
      "back_bay\n",
      "jamaica_plain\n",
      "south_end\n",
      "charlestown\n",
      "brighton\n",
      "allston\n",
      "west_end\n",
      "roslindale\n",
      "north_end\n",
      "mission_hill\n",
      "harbor_islands\n",
      "longwood_medical_area\n",
      "west_roxbury\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\r\n",
    "            \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\r\n",
    "            \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\r\n",
    "            \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\", \"\\xc2\", \"\\xa0\",\r\n",
    "            \"\\x80\", \"\\x9c\", \"\\x99\", \"\\x94\", \"\\xad\", \"\\xe2\", \"\\x9d\"]\r\n",
    "\r\n",
    "df_14 = pd.read_csv('./data-source/bostonglobe2014.csv')\r\n",
    "for char in spec_chars:\r\n",
    "    df_14['text'] = df_14['text'].str.replace(char, ' ')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data-source/bostonglobe2014.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e494730f4eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \"\\x80\", \"\\x9c\", \"\\x99\", \"\\x94\", \"\\xad\", \"\\xe2\", \"\\x9d\"]\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf_14\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data-source/bostonglobe2014.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspec_chars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdf_14\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_14\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data-source/bostonglobe2014.csv'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "788c7a583b49e0f108948e9844ef083ea97a54690da4d8e91da56fd70fa16a57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}